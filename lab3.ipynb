{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"HealthcareETL\").getOrCreate()\n",
    "\n",
    "file_path = \"healthcare_dataset.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+------+----------+-----------------+-----------------+----------------+--------------------+------------------+------------------+-----------+--------------+--------------+-----------+------------+\n",
      "|               Name|Age|Gender|Blood Type|Medical Condition|Date of Admission|          Doctor|            Hospital|Insurance Provider|    Billing Amount|Room Number|Admission Type|Discharge Date| Medication|Test Results|\n",
      "+-------------------+---+------+----------+-----------------+-----------------+----------------+--------------------+------------------+------------------+-----------+--------------+--------------+-----------+------------+\n",
      "|      Bobby JacksOn| 30|  Male|        B-|           Cancer|       2024-01-31|   Matthew Smith|     Sons and Miller|        Blue Cross|18856.281305978155|        328|        Urgent|    2024-02-02|Paracetamol|      Normal|\n",
      "|       LesLie TErRy| 62|  Male|        A+|          Obesity|       2019-08-20| Samantha Davies|             Kim Inc|          Medicare|33643.327286577885|        265|     Emergency|    2019-08-26|  Ibuprofen|Inconclusive|\n",
      "|        DaNnY sMitH| 76|Female|        A-|          Obesity|       2022-09-22|Tiffany Mitchell|            Cook PLC|             Aetna|27955.096078842456|        205|     Emergency|    2022-10-07|    Aspirin|      Normal|\n",
      "|       andrEw waTtS| 28|Female|        O+|         Diabetes|       2020-11-18|     Kevin Wells|Hernandez Rogers ...|          Medicare| 37909.78240987528|        450|      Elective|    2020-12-18|  Ibuprofen|    Abnormal|\n",
      "|      adrIENNE bEll| 43|Female|       AB+|           Cancer|       2022-09-19|  Kathleen Hanna|         White-White|             Aetna|14238.317813937623|        458|        Urgent|    2022-10-09| Penicillin|    Abnormal|\n",
      "|      EMILY JOHNSOn| 36|  Male|        A+|           Asthma|       2023-12-20|   Taylor Newton|      Nunez-Humphrey|  UnitedHealthcare| 48145.11095104189|        389|        Urgent|    2023-12-24|  Ibuprofen|      Normal|\n",
      "|     edwArD EDWaRDs| 21|Female|       AB-|         Diabetes|       2020-11-03|     Kelly Olson|     Group Middleton|          Medicare| 19580.87234486093|        389|     Emergency|    2020-11-15|Paracetamol|Inconclusive|\n",
      "| CHrisTInA MARtinez| 20|Female|        A+|           Cancer|       2021-12-28|  Suzanne Thomas|Powell Robinson a...|             Cigna| 45820.46272159459|        277|     Emergency|    2022-01-07|Paracetamol|Inconclusive|\n",
      "|    JASmINe aGuIlaR| 82|  Male|       AB+|           Asthma|       2020-07-01| Daniel Ferguson|       Sons Rich and|             Cigna|50119.222791548505|        316|      Elective|    2020-07-14|    Aspirin|    Abnormal|\n",
      "|   ChRISTopher BerG| 58|Female|       AB-|           Cancer|       2021-05-23|     Heather Day|      Padilla-Walker|  UnitedHealthcare| 19784.63106221073|        249|      Elective|    2021-06-22|Paracetamol|Inconclusive|\n",
      "|   mIchElLe daniELs| 72|  Male|        O+|           Cancer|       2020-04-19|     John Duncan|     Schaefer-Porter|          Medicare|12576.795609050234|        394|        Urgent|    2020-04-22|Paracetamol|      Normal|\n",
      "|     aaRon MARtiNeZ| 38|Female|        A-|     Hypertension|       2023-08-13|    Douglas Mayo|         Lyons-Blair|          Medicare| 7999.586879604188|        288|        Urgent|    2023-09-05|    Lipitor|Inconclusive|\n",
      "|      connOR HANsEn| 75|Female|        A+|         Diabetes|       2019-12-12|Kenneth Fletcher|Powers Miller, an...|             Cigna| 43282.28335770435|        134|     Emergency|    2019-12-28| Penicillin|    Abnormal|\n",
      "|       rObeRt bAuer| 68|Female|       AB+|           Asthma|       2020-05-22| Theresa Freeman|    Rivera-Gutierrez|  UnitedHealthcare|33207.706633729606|        309|        Urgent|    2020-06-19|    Lipitor|      Normal|\n",
      "|       bROOkE brady| 44|Female|       AB+|           Cancer|       2021-10-08| Roberta Stewart|     Morris-Arellano|  UnitedHealthcare|40701.599227308754|        182|        Urgent|    2021-10-13|Paracetamol|      Normal|\n",
      "| MS. nAtalIE gAMble| 46|Female|       AB-|          Obesity|       2023-01-01| Maria Dougherty|      Cline-Williams|        Blue Cross|12263.357425021362|        465|      Elective|    2023-01-11|    Aspirin|Inconclusive|\n",
      "|      haley perkins| 63|Female|        A+|        Arthritis|       2020-06-23|   Erica Spencer|     Cervantes-Wells|  UnitedHealthcare|24499.847903736576|        114|      Elective|    2020-07-14|Paracetamol|      Normal|\n",
      "|mRS. jamiE cAMPBELl| 38|  Male|       AB-|          Obesity|       2020-03-08|      Justin Kim|Torres, and Harri...|             Cigna|17440.465444124675|        449|        Urgent|    2020-04-02|Paracetamol|    Abnormal|\n",
      "|       LuKE BuRgEss| 34|Female|        A-|     Hypertension|       2021-03-04|Justin Moore Jr.|         Houston PLC|        Blue Cross| 18843.02301783416|        260|      Elective|    2021-03-14|    Aspirin|    Abnormal|\n",
      "|     dANIEL schmIdt| 63|  Male|        B+|           Asthma|       2022-11-15| Denise Galloway|         Hammond Ltd|             Cigna|23762.203579059587|        465|      Elective|    2022-11-22| Penicillin|      Normal|\n",
      "+-------------------+---+------+----------+-----------------+-----------------+----------------+--------------------+------------------+------------------+-----------+--------------+--------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of columns: 15\n",
      "Total number of rows: 55500\n",
      "Total number of duplicate rows: 534\n"
     ]
    }
   ],
   "source": [
    "total_columns = len(df.columns)\n",
    "print(f\"Total number of columns: {total_columns}\")\n",
    "\n",
    "total_rows = df.count()\n",
    "print(f\"Total number of rows: {total_rows}\")\n",
    "\n",
    "duplicate_count = total_rows - df.dropDuplicates().count()\n",
    "print(f\"Total number of duplicate rows: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, trim, initcap, lower, to_date, when, lit\n",
    "\n",
    "# Normalize Name\n",
    "cleaned_df = df.withColumn(\"Name\", initcap(col(\"Name\")))\n",
    "\n",
    "# Standardize Gender\n",
    "cleaned_df = cleaned_df.withColumn(\"Gender\", lower(trim(col(\"Gender\"))))\n",
    "\n",
    "# Convert Dates\n",
    "cleaned_df = cleaned_df.withColumn(\"Date of Admission\", to_date(col(\"Date of Admission\"), \"yyyy-MM-dd\"))\n",
    "cleaned_df = cleaned_df.withColumn(\"Discharge Date\", to_date(col(\"Discharge Date\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Fill Missing Values\n",
    "from pyspark.sql.functions import mean\n",
    "\n",
    "# Fill missing Billing Amount with the median\n",
    "median_value = cleaned_df.approxQuantile(\"Billing Amount\", [0.5], 0.0)[0]\n",
    "cleaned_df = cleaned_df.fillna({\"Billing Amount\": median_value})\n",
    "\n",
    "# Fill missing categorical values\n",
    "cleaned_df = cleaned_df.fillna({\n",
    "    \"Medical Condition\": \"Unknown\",\n",
    "    \"Doctor\": \"Unknown\",\n",
    "    \"Hospital\": \"Unknown\",\n",
    "    \"Insurance Provider\": \"Unknown\",\n",
    "    \"Admission Type\": \"Unknown\",\n",
    "    \"Medication\": \"Unknown\",\n",
    "    \"Test Results\": \"Unknown\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------------------+\n",
      "|Hospital                 |Total Billing     |\n",
      "+-------------------------+------------------+\n",
      "|Ramirez-Robinson         |96739.00128614204 |\n",
      "|Foster Lamb, Graham and  |10659.608812944593|\n",
      "|LLC Massey               |71446.9940966842  |\n",
      "|Coleman-Aguilar          |34961.90671326528 |\n",
      "|Group Stein              |25094.95572621151 |\n",
      "|Smith PLC                |1029424.449116314 |\n",
      "|Alvarado-Martin          |1077.1696809399066|\n",
      "|Hall Group               |247201.21558231176|\n",
      "|and Mayo Chen, Murray    |49400.214028011644|\n",
      "|Lopez-Wilson             |56481.55593873338 |\n",
      "|Harris-Farrell           |32166.967383439547|\n",
      "|Dawson-Williams          |9616.626025733382 |\n",
      "|Holmes Reed and Johnson, |9492.225487246009 |\n",
      "|and Lee Rodriguez Morris,|18047.5510046168  |\n",
      "|Watkins, and Young Perry |41838.22082511615 |\n",
      "|Nunez-Hamilton           |40446.09173896364 |\n",
      "|Freeman-Hunter           |29414.68600622586 |\n",
      "|and Aguilar Sons         |92686.82176385348 |\n",
      "|Reeves-Edwards           |21847.12682622056 |\n",
      "|Williams-Russell         |12447.792836846635|\n",
      "+-------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove invalid ages\n",
    "cleaned_df = cleaned_df.filter((col(\"Age\") > 0) & (col(\"Age\") <= 120))\n",
    "\n",
    "# Remove records with missing Room Number\n",
    "cleaned_df = cleaned_df.na.drop(subset=[\"Room Number\"])\n",
    "\n",
    "# Aggregate Billing Amount by Hospital\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "billing_summary = cleaned_df.groupBy(\"Hospital\").agg(sum(\"Billing Amount\").alias(\"Total Billing\"))\n",
    "billing_summary.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+------+----------+-----------------+-----------------+---------------------+------------------------------+------------------+------------------+-----------+--------------+--------------+-----------+------------+\n",
      "|Name                |Age|Gender|Blood Type|Medical Condition|Date of Admission|Doctor               |Hospital                      |Insurance Provider|Billing Amount    |Room Number|Admission Type|Discharge Date|Medication |Test Results|\n",
      "+--------------------+---+------+----------+-----------------+-----------------+---------------------+------------------------------+------------------+------------------+-----------+--------------+--------------+-----------+------------+\n",
      "|maTthEw SEllERS     |71 |Female|O-        |Cancer           |2021-02-06       |Erin Page            |Brown-Cortez                  |UnitedHealthcare  |47566.507842139574|400        |Emergency     |2021-02-10    |Ibuprofen  |Abnormal    |\n",
      "|samUel brYaNt       |53 |Male  |O+        |Arthritis        |2023-03-14       |Cheryl Crawford      |Morris, Gallegos and Harrison |UnitedHealthcare  |22303.346230419313|382        |Emergency     |2023-03-31    |Paracetamol|Abnormal    |\n",
      "|rOberT king         |39 |Male  |O+        |Arthritis        |2021-08-10       |Joyce Hill           |Christensen and Parker Jones, |Blue Cross        |35811.154114344834|339        |Urgent        |2021-08-26    |Paracetamol|Abnormal    |\n",
      "|EdWArd caRdENaS     |80 |Male  |A+        |Arthritis        |2021-08-19       |Heather Wright       |and Ali Snyder Hughes,        |UnitedHealthcare  |28847.107951613794|427        |Urgent        |2021-08-26    |Ibuprofen  |Normal      |\n",
      "|Linda rObErTs       |68 |Male  |AB-       |Hypertension     |2021-12-05       |Teresa Gardner       |Inc Diaz                      |UnitedHealthcare  |4267.546191834819 |392        |Urgent        |2021-12-12    |Lipitor    |Normal      |\n",
      "|CArL TaYlOr         |80 |Female|B+        |Cancer           |2020-04-02       |Brenda Jones         |Sons Adams and                |Medicare          |6624.735890351812 |459        |Urgent        |2020-04-25    |Aspirin    |Inconclusive|\n",
      "|miCHaeL BrADLEY     |22 |Male  |O+        |Arthritis        |2022-08-22       |Lisa Howell          |Olsen LLC                     |UnitedHealthcare  |7647.467841405351 |218        |Emergency     |2022-09-15    |Penicillin |Inconclusive|\n",
      "|ANdrEa Wade         |25 |Male  |O-        |Obesity          |2019-12-12       |Jeffrey Mcintosh     |Ltd Perez                     |UnitedHealthcare  |7122.4605300368585|393        |Emergency     |2020-01-03    |Aspirin    |Abnormal    |\n",
      "|Dawn whitE          |73 |Female|AB-       |Hypertension     |2020-01-10       |Kimberly Green       |Flores-Glass                  |UnitedHealthcare  |2707.7082524511943|356        |Elective      |2020-01-21    |Penicillin |Inconclusive|\n",
      "|KeNneth CrAWFORd DdS|30 |Female|B-        |Diabetes         |2022-06-08       |Bethany Anderson     |Baker Elliott and Miller,     |UnitedHealthcare  |42230.593911981974|176        |Elective      |2022-06-16    |Penicillin |Normal      |\n",
      "|niCHOlas mENdOza    |39 |Male  |AB+       |Hypertension     |2023-09-01       |Rachel Gibson        |Lewis Ltd                     |Blue Cross        |42799.7762302189  |321        |Elective      |2023-09-03    |Lipitor    |Normal      |\n",
      "|tRAvis bAKEr        |81 |Male  |B+        |Hypertension     |2021-02-23       |Carolyn Johnson      |Group Alvarado                |Medicare          |27091.028236828883|382        |Urgent        |2021-03-23    |Aspirin    |Abnormal    |\n",
      "|kiM HAMILTON        |26 |Male  |O-        |Hypertension     |2021-12-08       |Sarah Evans          |Torres-Fischer                |Cigna             |44540.90468037528 |168        |Elective      |2021-12-30    |Lipitor    |Abnormal    |\n",
      "|KYle REEd           |59 |Female|AB+       |Obesity          |2022-08-28       |Stacy Bender         |Moore-Sanders                 |Cigna             |28954.26139161208 |379        |Emergency     |2022-09-14    |Aspirin    |Inconclusive|\n",
      "|mArY WatKins        |32 |Female|A-        |Asthma           |2021-02-08       |Sean Avila           |Boyle PLC                     |Blue Cross        |38896.40092179493 |121        |Elective      |2021-02-19    |Penicillin |Abnormal    |\n",
      "|tIfFaNy GARDnEr     |29 |Male  |AB-       |Hypertension     |2019-05-26       |Evan White           |Mckenzie Maldonado, Acosta and|Medicare          |37425.119008199836|202        |Elective      |2019-06-22    |Lipitor    |Abnormal    |\n",
      "|maRIa tHOMAS        |61 |Male  |B+        |Hypertension     |2021-08-28       |Cheryl Malone        |and Cantu, Hunter Wang        |Medicare          |34398.02619633796 |296        |Urgent        |2021-09-10    |Paracetamol|Abnormal    |\n",
      "|marY JOneS          |41 |Male  |B-        |Obesity          |2019-07-02       |Mr. Lawrence Adams MD|and Smith Smith, Ryan         |Cigna             |34290.947528102886|171        |Urgent        |2019-07-09    |Paracetamol|Abnormal    |\n",
      "|cOdy wRiGht         |73 |Female|A+        |Obesity          |2019-10-23       |Veronica Herrera     |Ltd Martinez                  |Blue Cross        |35533.994157346606|179        |Emergency     |2019-11-22    |Lipitor    |Normal      |\n",
      "|mICHAEL PoLlArD     |40 |Female|AB+       |Diabetes         |2023-08-21       |Anthony Hobbs        |Gentry-Thompson               |Cigna             |35190.49665754021 |115        |Urgent        |2023-08-24    |Lipitor    |Abnormal    |\n",
      "+--------------------+---+------+----------+-----------------+-----------------+---------------------+------------------------------+------------------+------------------+-----------+--------------+--------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, col\n",
    "\n",
    "# Find and show duplicate rows\n",
    "duplicates_df = df.groupBy(df.columns).agg(count(\"*\").alias(\"count\")).filter(col(\"count\") > 1).drop(\"count\")\n",
    "duplicates_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+------+----------+-----------------+-----------------+-------------------+------------------------------+------------------+------------------+-----------+--------------+--------------+-----------+------------+\n",
      "|Name              |Age|Gender|Blood Type|Medical Condition|Date of Admission|Doctor             |Hospital                      |Insurance Provider|Billing Amount    |Room Number|Admission Type|Discharge Date|Medication |Test Results|\n",
      "+------------------+---+------+----------+-----------------+-----------------+-------------------+------------------------------+------------------+------------------+-----------+--------------+--------------+-----------+------------+\n",
      "|James Ross        |83 |female|A+        |Diabetes         |2024-01-13       |Michael Baker      |Cox-Hester                    |Blue Cross        |10352.20848674086 |394        |Urgent        |2024-01-22    |Aspirin    |Abnormal    |\n",
      "|Andrea Allen      |47 |female|AB+       |Obesity          |2019-06-09       |David Lindsey      |and Mendoza Rich Morales,     |UnitedHealthcare  |25574.127619098694|464        |Elective      |2019-07-01    |Aspirin    |Inconclusive|\n",
      "|Mr. Timothy Flores|77 |male  |A-        |Arthritis        |2020-07-07       |Margaret Ramos     |Parker-Shannon                |Medicare          |40196.82527780484 |152        |Urgent        |2020-08-05    |Paracetamol|Abnormal    |\n",
      "|Jennifer Camacho  |83 |male  |AB-       |Asthma           |2019-10-28       |Mark Watson        |Cunningham-King               |UnitedHealthcare  |24023.95612282017 |118        |Elective      |2019-11-24    |Ibuprofen  |Inconclusive|\n",
      "|Dana Williamson   |46 |male  |A+        |Hypertension     |2022-05-16       |Daniel Thomas      |and Sons Nelson               |Aetna             |10443.206903000886|408        |Elective      |2022-05-31    |Aspirin    |Inconclusive|\n",
      "|Joseph Gutierrez  |82 |male  |A+        |Obesity          |2024-03-10       |Christopher Mills  |Avery and Sons                |Cigna             |27512.913169434043|442        |Emergency     |2024-04-07    |Aspirin    |Normal      |\n",
      "|Matthew Haley     |81 |male  |A+        |Arthritis        |2020-02-24       |Joann Anderson     |Oliver Griffin Johnson, and   |Blue Cross        |19698.000742558204|279        |Elective      |2020-03-16    |Paracetamol|Abnormal    |\n",
      "|Vanessa Martin    |77 |male  |O+        |Arthritis        |2019-08-25       |Heather Bowman     |Cunningham Andrade and Butler,|Cigna             |46134.92597863609 |107        |Elective      |2019-09-04    |Aspirin    |Inconclusive|\n",
      "|Rebecca James     |61 |male  |O+        |Hypertension     |2023-03-31       |Stacie Andrade     |Thompson-Brown                |Cigna             |10898.20876297997 |476        |Elective      |2023-04-12    |Penicillin |Inconclusive|\n",
      "|Antonio Contreras |37 |male  |O-        |Asthma           |2023-12-11       |Audrey Fleming     |Lin-Alexander                 |UnitedHealthcare  |45775.20384648719 |407        |Elective      |2023-12-14    |Ibuprofen  |Normal      |\n",
      "|Robert Robbins    |42 |male  |AB+       |Diabetes         |2024-01-07       |John Woodard       |Fuller Perez Scott, and       |Cigna             |23890.559941311687|493        |Emergency     |2024-01-25    |Ibuprofen  |Inconclusive|\n",
      "|Daniel Howard     |57 |female|O-        |Asthma           |2023-10-10       |Michael Burns      |Buck PLC                      |Aetna             |44276.4174208084  |436        |Elective      |2023-11-02    |Aspirin    |Normal      |\n",
      "|Brian Mayer       |85 |male  |B-        |Diabetes         |2021-02-15       |Holly Smith        |Garcia Obrien, Casey and      |Aetna             |17860.21344103559 |374        |Emergency     |2021-02-24    |Lipitor    |Normal      |\n",
      "|Kayla Smith       |29 |male  |A-        |Asthma           |2023-08-27       |James Dixon        |Fisher-Mclean                 |Blue Cross        |34829.84620553869 |322        |Urgent        |2023-09-08    |Lipitor    |Abnormal    |\n",
      "|Vincent Martin    |82 |male  |A+        |Arthritis        |2021-07-21       |Marcus Booker      |Murphy-West                   |Cigna             |9796.417212466917 |275        |Emergency     |2021-08-17    |Ibuprofen  |Inconclusive|\n",
      "|Valerie Morris    |63 |female|A-        |Asthma           |2020-11-02       |Evelyn Boyd        |Estes, Logan and Smith        |Aetna             |7526.90594717944  |189        |Elective      |2020-11-04    |Ibuprofen  |Abnormal    |\n",
      "|Lori House        |56 |female|O+        |Diabetes         |2023-10-26       |Tyler Fox          |Rodriguez Group               |Aetna             |28813.187617716405|184        |Urgent        |2023-11-09    |Lipitor    |Normal      |\n",
      "|Kelly Torres      |47 |female|O-        |Obesity          |2024-03-21       |Cynthia Mcdowell   |Sons and Conley               |Blue Cross        |37394.489377877275|477        |Elective      |2024-04-10    |Lipitor    |Normal      |\n",
      "|Amanda Pearson    |63 |male  |AB+       |Hypertension     |2020-03-14       |Mr. Tommy Underwood|Lee Brewer and Walters,       |Aetna             |13772.734419303699|409        |Elective      |2020-03-30    |Paracetamol|Abnormal    |\n",
      "|Jamie Mcdonald    |50 |male  |A-        |Cancer           |2022-03-02       |Ashley Mendoza     |LLC Wong                      |UnitedHealthcare  |34325.24003837843 |378        |Elective      |2022-03-22    |Aspirin    |Normal      |\n",
      "+------------------+---+------+----------+-----------------+-----------------+-------------------+------------------------------+------------------+------------------+-----------+--------------+--------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cleaned_df = cleaned_df.dropDuplicates()\n",
    "\n",
    "cleaned_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of columns: 15\n",
      "Total number of rows: 54966\n",
      "Total number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_columns = len(cleaned_df.columns)\n",
    "print(f\"Total number of columns: {total_columns}\")\n",
    "\n",
    "total_rows = cleaned_df.count()\n",
    "print(f\"Total number of rows: {total_rows}\")\n",
    "\n",
    "duplicate_count = total_rows - df.dropDuplicates().count()\n",
    "print(f\"Total number of duplicate rows: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o435.csv.\n: java.lang.UnsatisfiedLinkError: 'boolean org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(java.lang.String, int)'\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)\r\n\tat org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249)\r\n\tat org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:275)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:392)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:420)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:392)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:860)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:842)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaned_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcleaned_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoalesce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Spark\\spark-3.5.4\\python\\pyspark\\sql\\readwriter.py:1864\u001b[0m, in \u001b[0;36mDataFrameWriter.csv\u001b[1;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode(mode)\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[0;32m   1847\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   1848\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1862\u001b[0m     lineSep\u001b[38;5;241m=\u001b[39mlineSep,\n\u001b[0;32m   1863\u001b[0m )\n\u001b[1;32m-> 1864\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\Spark\\spark-3.5.4\\python\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o435.csv.\n: java.lang.UnsatisfiedLinkError: 'boolean org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(java.lang.String, int)'\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)\r\n\tat org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:793)\r\n\tat org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1249)\r\n\tat org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1454)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:761)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972)\r\n\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:192)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:552)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:275)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:392)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:420)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:392)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:243)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:860)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:842)\r\n"
     ]
    }
   ],
   "source": [
    "output_path = \"cleaned_data.csv\"\n",
    "cleaned_df.coalesce(1).write.mode(\"overwrite\").csv(output_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
